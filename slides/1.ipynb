{
 "metadata": {
  "celltoolbar": "Slideshow",
  "name": "",
  "signature": "sha256:155d966fdfb45501f4d1efef4ffe62516b756ba71d6f044690ba82d06f1b0256"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Section 1-1 - Filling-in Missing Values"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the previous section, we ended up with a smaller set of predictions because we chose to throw away rows with missing values. We build on this approach in this section by filling in the missing data with an educated guess."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will only provide detailed descriptions on new concepts introduced."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Pandas - Extracting data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "df = pd.read_csv('../data/train.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Pandas - Cleaning data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = df.drop(['Name', 'Ticket', 'Cabin'], axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Similar to the previous section, we review the data type and value counts."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 891 entries, 0 to 890\n",
        "Data columns (total 9 columns):\n",
        "PassengerId    891 non-null int64\n",
        "Survived       891 non-null int64\n",
        "Pclass         891 non-null int64\n",
        "Sex            891 non-null object\n",
        "Age            714 non-null float64\n",
        "SibSp          891 non-null int64\n",
        "Parch          891 non-null int64\n",
        "Fare           891 non-null float64\n",
        "Embarked       889 non-null object\n",
        "dtypes: float64(2), int64(5), object(2)"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "There are a number of ways that we could fill in the NaN values of the column Age. For simplicity, we'll do so by taking the average, or mean, of values of each column. We'll review as to whether taking the median would be a better choice in a later section."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "age_mean = df['Age'].mean()\n",
      "df['Age'] = df['Age'].fillna(age_mean)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Taking the average does not make sense for the column Embarked, as it is a categorical value. Instead, we shall replace the NaN values by the mode, or most frequently occurring value."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import mode\n",
      "\n",
      "mode_embarked = mode(df['Embarked'])[0][0]\n",
      "df['Embarked'] = df['Embarked'].fillna(mode_embarked)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['Gender'] = df['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
      "df['Port'] = df['Embarked'].map({'C':1, 'S':2, 'Q':3}).astype(int)\n",
      "\n",
      "df = df.drop(['Sex', 'Embarked'], axis=1)\n",
      "\n",
      "cols = df.columns.tolist()\n",
      "cols = [cols[1]] + cols[0:1] + cols[2:]\n",
      "df = df[cols]"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "We now review details of our training data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 891 entries, 0 to 890\n",
        "Data columns (total 9 columns):\n",
        "Survived       891 non-null int64\n",
        "PassengerId    891 non-null int64\n",
        "Pclass         891 non-null int64\n",
        "Age            891 non-null float64\n",
        "SibSp          891 non-null int64\n",
        "Parch          891 non-null int64\n",
        "Fare           891 non-null float64\n",
        "Gender         891 non-null int64\n",
        "Port           891 non-null int64\n",
        "dtypes: float64(2), int64(7)"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Hence have we have preserved all the rows of our data set, and proceed to create a numerical array for Scikit-learn."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_data = df.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Scikit-learn - Training the model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "model = RandomForestClassifier(n_estimators = 100)\n",
      "model = model.fit(train_data[0:,2:],train_data[0:,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Scikit-learn - Making predictions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_test = pd.read_csv('../data/test.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "We now review what needs to be cleaned in the test data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_test.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 418 entries, 0 to 417\n",
        "Data columns (total 11 columns):\n",
        "PassengerId    418 non-null int64\n",
        "Pclass         418 non-null int64\n",
        "Name           418 non-null object\n",
        "Sex            418 non-null object\n",
        "Age            332 non-null float64\n",
        "SibSp          418 non-null int64\n",
        "Parch          418 non-null int64\n",
        "Ticket         418 non-null object\n",
        "Fare           417 non-null float64\n",
        "Cabin          91 non-null object\n",
        "Embarked       418 non-null object\n",
        "dtypes: float64(2), int64(4), object(5)"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As per our previous approach, we drop the less relevant columns and fill in the NaN values in the column Age with the mean."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_test = df_test.drop(['Name', 'Ticket', 'Cabin'], axis=1)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_test['Age'] = df_test['Age'].fillna(age_mean)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "For the column Fare, however, it makes sense to fill in the NaN values with the mean by the column Pclass, or Passenger class."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fare_means = df.pivot_table('Fare', index='Pclass', aggfunc='mean')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fare_means"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "Pclass\n",
        "1         84.154687\n",
        "2         20.662183\n",
        "3         13.675550\n",
        "Name: Fare, dtype: float64"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we created a pivot table by calculating the mean of the column Fare by each Pclass, which we will use to fill in our NaN values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_test['Fare'] = df_test[['Fare', 'Pclass']].apply(lambda x:\n",
      "                            fare_means[x['Pclass']] if pd.isnull(x['Fare'])\n",
      "                            else x['Fare'], axis=1)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is one of the more complicated lines of code we'll encounter, so let's unpack this."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, we look at each of the pairs (Fare, Pclass) (i.e. lambda x). From this pair, we check if the Fare part is NaN (i.e. if pd.isnull(x['Fare'])). If Fare is NaN, we look at the Pclass value of that pair (i.e. x['PClass']), and replace the NaN value the mean fare of that class (i.e. fare_means[x['Pclass']]). If Fare is not NaN, then we keep it the same (i.e. else x['Fare'])."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_test['Gender'] = df_test['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
      "df_test['Port'] = df_test['Embarked'].map({'C':1, 'S':2, 'Q':3})\n",
      "\n",
      "df_test = df_test.drop(['Sex', 'Embarked'], axis=1)\n",
      "\n",
      "test_data = df_test.values\n",
      "\n",
      "output = model.predict(test_data[:,1:])"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Pandas - Preparing for submission"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = np.c_[test_data[:,0].astype(int), output.astype(int)]\n",
      "df_result = pd.DataFrame(result[:,0:2], columns=['PassengerId', 'Survived'])\n",
      "\n",
      "df_result.to_csv('../results/titanic_1-1.csv', index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Now we'll discover that our submission has 418 predictions, and can proceed to make our first leaderboard entry."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "https://www.kaggle.com/c/titanic-gettingStarted/submissions/attach"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_result.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "(418, 2)"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Congratulations on making your first Kaggle submission!! In [Section 1-2](http://slideviewer.herokuapp.com/github/savarin/pyconuk-introtutorial/blob/master/slides/2.ipynb#/), we'll discuss how to create dummy variables."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}